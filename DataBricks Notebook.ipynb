{"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"environmentMetadata":null,"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"databrick","widgets":{}},"language_info":{"name":""},"kernelspec":{"name":"","display_name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"storageAccountName = \"casestudy02\"\nappID = \"486642b5-cbc7-41d2-b032-79f54047c5b4\"\nsecret = \"qeq8Q~dR4xj~JLgrLEOW-Iai~28VNA~A3yZjjcTU\"\nfileSystemName = \"input\"\ntenantID = \"96330ec5-4405-49df-8fef-81647408f9f8\"\n\nspark.conf.set(\"fs.azure.account.auth.type.\" + storageAccountName + \".dfs.core.windows.net\", \"OAuth\")\nspark.conf.set(\"fs.azure.account.oauth.provider.type.\" + storageAccountName + \".dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\nspark.conf.set(\"fs.azure.account.oauth2.client.id.\" + storageAccountName + \".dfs.core.windows.net\", \"\" + appID + \"\")\nspark.conf.set(\"fs.azure.account.oauth2.client.secret.\" + storageAccountName + \".dfs.core.windows.net\", \"\" + secret + \"\")\nspark.conf.set(\"fs.azure.account.oauth2.client.endpoint.\" + storageAccountName + \".dfs.core.windows.net\", \"https://login.microsoftonline.com/\" + tenantID + \"/oauth2/token\")\nspark.conf.set(\"fs.azure.createRemoteFileSystemDuringInitialization\", \"true\")\ndbutils.fs.ls(\"abfss://\" + fileSystemName  + \"@\" + storageAccountName + \".dfs.core.windows.net/\")\nspark.conf.set(\"fs.azure.createRemoteFileSystemDuringInitialization\", \"false\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e07be1ee-48d0-471d-9225-d749c705ae9c","showTitle":false,"title":""}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%scala\nval neww = spark.read.format(\"csv\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .load(\"abfss://input@casestudy02.dfs.core.windows.net/*.csv\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7f79c241-0c80-4390-bbce-15cb31f123ec","showTitle":false,"title":""}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">neww: org.apache.spark.sql.DataFrame = [transaction_id: int, product_id: int ... 2 more fields]\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">neww: org.apache.spark.sql.DataFrame = [transaction_id: int, product_id: int ... 2 more fields]\n</div>","datasetInfos":[{"name":"neww","schema":{"fields":[{"metadata":{},"name":"transaction_id","nullable":true,"type":"integer"},{"metadata":{},"name":"product_id","nullable":true,"type":"integer"},{"metadata":{},"name":"sales_amount","nullable":true,"type":"double"},{"metadata":{"__detected_date_formats":"yyyy-M-d"},"name":"sales_date","nullable":true,"type":"date"}],"type":"struct"},"tableIdentifier":null,"typeStr":"org.apache.spark.sql.DataFrame"}],"metadata":{"isDbfsCommandResult":false},"removedWidgets":[],"type":"html"}}}]},{"cell_type":"code","source":"# Configure JDBC URL\njdbcHostname = \"sqlserver://casestudysynapse.sql.azuresynapse.net\"\njdbcPort = \"1433\"\njdbcDatabase = \"case\"\njdbcUsername = \"User\"\njdbcPassword = \"Admin@123\"\n\n# Connection properties\nconnectionProperties = {\n    \"user\" : jdbcUsername,\n    \"password\" : jdbcPassword,\n    \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n}\n\njdbcUrl = f\"jdbc:sqlserver://casestudysynapse.sql.azuresynapse.net:1433;database=case study pool;user=undefined@casestudysynapse;password=Admin@123;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.sql.azuresynapse.net;loginTimeout=30;\"\n","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9ab834de-3d45-4579-9d98-306adb056565","showTitle":false,"title":""}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import IntegerType, DoubleType, DateType\n\n# Read CSV files from Azure Data Lake Storage\ndf = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"abfss://input@(link unavailable)\")\n\n# Data cleaning and transformation\ndf = df.withColumn(\"transaction_id\", F.col(\"transaction_id\").cast(IntegerType()))\ndf = df.withColumn(\"product_id\", F.col(\"product_id\").cast(IntegerType()))\ndf = df.withColumn(\"sales_amount\", F.col(\"sales_amount\").cast(DoubleType()))\ndf = df.withColumn(\"sales_date\", F.to_date(F.col(\"sales_date\"), \"yyyy-MM-dd\").cast(DateType()))\n\n# Remove null values\ndf = df.dropna()\n\n# Aggregate sales data\nagg_df = df.groupBy(\"product_id\").agg(F.sum(\"sales_amount\").alias(\"total_sales\"))\n\n# Write transformed data back to Azure Synapse Analytics\njdbcUrl = \"jdbc:sqlserver://casestudysynapse.(link unavailable):1433;database=case study pool;user=undefined@casestudysynapse;password=Admin@123;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.(link unavailable);loginTimeout=30\"\n\n# Write to Azure Synapse Analytics\nagg_df.write.jdbc(jdbcUrl, \"sales_data\", mode(\"overwrite\"), properties={\"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"})","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8a1cffa1-f595-4e5f-9132-68218897db8e","showTitle":false,"title":""}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agg_df.write.jdbc(url=jdbcUrl, table=\"Final1\", mode=\"overwrite\", properties=connectionProperties)","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d2fa5ba1-c359-4c39-8ee5-91e58a9223c0","showTitle":false,"title":""}},"execution_count":null,"outputs":[]}]}